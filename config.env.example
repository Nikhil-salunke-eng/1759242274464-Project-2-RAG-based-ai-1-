# Ollama Configuration (for local LLM)
OLLAMA_URL=http://localhost:11434
EMBEDDING_MODEL=bge-m3
LLM_MODEL=llama3.2

# OpenAI Configuration (alternative to Ollama)
OPENAI_API_KEY=your_openai_api_key_here

# Anthropic Configuration (alternative to Ollama)
ANTHROPIC_API_KEY=your_anthropic_api_key_here

# Application Configuration
EMBEDDINGS_PATH=embeddings.joblib
PORT=8501

